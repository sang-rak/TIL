# 빅데이터 분석기사 실기 준비

1. 작업형

   ![image-20210613190631927](빅데이터 분석기사 실기 준비.assets/image-20210613190631927.png)

```python
import pandas as pd
import numpy as np

df = pd.read_csv('data/mtcars.csv')
subdf = df['qsec']
x = subdf.values.reshape(-1,1)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
y = scaler.fit_transform(x)

print((y>0.5).sum())
```



2. 작업형 

   ![image-20210613191448268](빅데이터 분석기사 실기 준비.assets/image-20210613191448268.png)

   ![image-20210613191508183](빅데이터 분석기사 실기 준비.assets/image-20210613191508183.png)

   ![image-20210613191547301](빅데이터 분석기사 실기 준비.assets/image-20210613191547301.png)

   ![image-20210613191613114](빅데이터 분석기사 실기 준비.assets/image-20210613191613114.png)

```python
import pandas as pd

y_train = pd.read_csv('data/y_train.csv')
X_train = pd.read_csv('data/X_train.csv', encoding='UTF8')
test = pd.read_csv('data/X_test.csv', encoding='UTF8')

## 데이터 load
# Q1 y_train, X_train 데이터를 합쳐 trainDf 변수에 저장하라
trainDf = pd.merge(y_train,X_train)
print(trainDf.head(3))

## 데이터 전처리
# 데이터 타입 확인
print(trainDf.info())

# Q2 trainDf와 X_test의 결측치가 있는 컬럼의 숫자 및 결측치 숫자를 파악하고 결측치처리 방식에 대해 생각해보자
trainNAN = pd.isnull(trainDf).sum()
print(trainNAN)
testNAN = pd.isnull(test).sum()
print(testNAN)
isnullGender = trainDf[trainDf['환불금액'].isnull()].gender.value_counts()
print(isnullGender.index)
print(isnullGender.values)
print(trainDf['환불금액'].describe())

# null값 0으로 채우기
trainDf['환불금액'] = trainDf['환불금액'].fillna(0)
test['환불금액'] = test['환불금액'].fillna(0)
print(trainDf)
print(test)

# Q3 범주형 변수의 유일값과 유일값의 갯수를 파악하라
main_index = trainDf['주구매상품'].value_counts().index
print('상품 수:', len(main_index))
print('상품 리스트:', list(main_index))

main_center = trainDf['주구매지점'].value_counts().index
print('지점 수:', len(main_center))
print('지점 리스트:', list(main_center))

## 데이터 모델링
from sklearn.model_selection import train_test_split

x = trainDf.drop(['cust_id','gender'],axis=1)
y = trainDf.gender

x_dum = pd.get_dummies(x)
feature_name_lit = x_dum.columns

test_dum = pd.get_dummies(test)

# test에 없는 train features 채우기
missing_cols = set( x_dum.columns ) - set( test_dum.columns )
for c in missing_cols:
	test_dum[c] = 0
test_dum = test_dum[x_dum.columns]

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
sc.fit(x_dum)
x_dum = sc.transform(x_dum)
text_dum = sc.transform(test_dum)

X_train, X_test, y_train, y_test = train_test_split(x_dum, y, test_size=0.3, random_state=60, stratify=y)
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(max_depth=2, random_state=0)
clf.fit(X_train, y_train)

from sklearn.metrics import classification_report
y_pred = clf.predict(X_test)
report = classification_report(y_test, y_pred, target_names=['class 0', 'class 1'])
print(report)

from sklearn.metrics import roc_auc_score, roc_curve
lr_probs = clf.predict_proba(X_test)
lr_auc = roc_auc_score(y_test, lr_probs[:, 1])
print(lr_auc)


from xgboost import XGBClassifier
from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold

# Gradient boosting tunning
kfold = StratifiedKFold(n_splits=10)

# GBC_best 를 xgboost로 수정
GBC = GradientBoostingClassifier()
gb_param_grid = {
              # 'n_estimators' : [100,200,300],
              # 'learning_rate': [0.1, 0.05, 0.01],
              # 'max_depth': [4, 8],
              }

gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring="accuracy", n_jobs= 4, verbose = 1)
gsGBC.fit(x_dum,y)
GBC_best = gsGBC.best_estimator_

print(gsGBC.best_score_)

# RFC Parameters tunning 
RFC = RandomForestClassifier()


## Search grid for optimal parameters
rf_param_grid = {"max_depth": [None],
              # "max_features": [1, 3, 10],
              # "n_estimators" :[100,300],
								}

gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring="accuracy", n_jobs= 4, verbose = 1)
gsRFC.fit(x_dum,y)
RFC_best = gsRFC.best_estimator_

print(gsRFC.best_score_)
								 
votingC = VotingClassifier(estimators=[('rfc', RFC_best),('gbc',GBC_best)], voting='soft', n_jobs=4)

votingC = votingC.fit(x_dum,y)

test_gender = pd.Series(votingC.predict_proba(test_dum)[:,1], name="gender")
results= pd.concat([test.cust_id,test_gender],axis=1)
results.head(3)
print(results)
results.to_csv("ensemble_voting.csv",index=False)
```

