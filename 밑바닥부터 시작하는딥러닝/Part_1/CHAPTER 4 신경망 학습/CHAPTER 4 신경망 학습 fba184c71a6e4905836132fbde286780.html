<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>CHAPTER 4 신경망 학습</title><style>
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}
.select-value-color-default { background-color: rgba(206,205,202,0.5); }
.select-value-color-gray { background-color: rgba(155,154,151, 0.4); }
.select-value-color-brown { background-color: rgba(140,46,0,0.2); }
.select-value-color-orange { background-color: rgba(245,93,0,0.2); }
.select-value-color-yellow { background-color: rgba(233,168,0,0.2); }
.select-value-color-green { background-color: rgba(0,135,107,0.2); }
.select-value-color-blue { background-color: rgba(0,120,223,0.2); }
.select-value-color-purple { background-color: rgba(103,36,222,0.2); }
.select-value-color-pink { background-color: rgba(221,0,129,0.2); }
.select-value-color-red { background-color: rgba(255,0,26,0.2); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="44daccad-c738-4ba1-83cf-6a8856a10ee1" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">🔸</span></div><h1 class="page-title">CHAPTER 4 신경망 학습</h1></header><div class="page-body"><nav id="f013b9cc-90a9-4c6d-b77d-8d9490d992fc" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#78fa75f3-ce21-4060-b8d2-4d8bc97c8bb8">1. 데이터에서 학습한다!</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#a36e0fcb-2dce-4cd8-8921-2d2bc98261e3">1.1 데이터 주도학습</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ab22744d-ce8f-4980-b05b-052efdf5766b">1.2 훈련 데이터와 시험 데이터</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#fe18ab4b-3504-490f-9e5d-0aa341b3e5ba">2. 손실 함수</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#1fa307b2-2168-4782-99d5-8eaeef59cedc">2.1 오차제곱합</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#2d5038ba-b88f-4d17-892e-2ec37da69afd">2.2. 교차 엔트로피 오차</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#4ca2d94f-21b0-4c76-92fa-1d7213ae412d">2.3 미니배치 학습</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#43347660-c0cc-4e74-8bd4-6f75b2d9b038">2.4 (배치용) 교차 엔트로피 오차 구현하기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#c73cec60-982c-4ad7-b2f9-db6a6a21ee62">2.5 왜 손실 함수를 설정하는가?</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#59d2a380-9dd2-43cf-9239-ab3030661d31">3. 수치 미분</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#5a0dc621-6618-43e4-b871-abf1f64a8d8b">3.1 미분</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#23192ffe-a32c-41ff-b9f8-402886fbe70d">3.2 수치 미분의 예</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#d492c191-8692-4e08-9f29-7a1369bfde4b">3.3 편미분</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#e829f8c1-efcb-43b6-b148-449097109e24">4. 기울기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#a63a9861-928e-4049-9774-225b863457f8">4.1 경사법(경사 하강법)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#1cd4ef37-86c4-4893-905a-ab0d25866bfb">4.2 신경망에서의 기울기</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#47d42042-e5c4-4351-82f0-a53bd6004ed3">5. 학습 알고리즘 구현하기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#3b4489c7-843b-4a9c-b6fd-ddf72f2cde57">5.1 2층 신경망 클래스 구현하기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#21e7f4d6-1b78-40d5-a58d-3cf3e6b0975d">5.2 미니배치 학습 구현하기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#46b16d6f-167f-43bd-a9c4-9a2e2f5baf01">5.3 시험 데이터로 평가하기</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#3345f9c7-4bab-4f41-8d19-51a3913dc6d1">6. 정리</a></div></nav><h1 id="78fa75f3-ce21-4060-b8d2-4d8bc97c8bb8" class="">1. 데이터에서 학습한다!</h1><ul id="9940c29c-8879-439c-9a67-b29988776832" class="bulleted-list"><li>손실함수: 신경망이 학습 할 수 있도록 해주는 지표</li></ul><ul id="ab3a7cfd-a801-4357-956c-f12cbd8624f4" class="bulleted-list"><li>신경망 학습: 데이터로부터 매개변수의 값을 정하는 방법</li></ul><p id="9525398d-55a6-4ba0-b3ee-9d83129ee218" class="">
</p><p id="8cc810c7-554b-4406-98b8-97c34e56ac39" class="">2장의 퍼셉트론(선방향)은 선형분리가능 문제라면 퍼셉트론 수렴정리를 통해 데이터로 부터 자동으로 학습 가능하지만 비선형 분리 문제는 자동으로 학습 할 수 없습니다.</p><p id="83368d03-2a67-40f0-861a-9f7b4a6bf6b7" class="">
</p><h2 id="a36e0fcb-2dce-4cd8-8921-2d2bc98261e3" class="">1.1 데이터 주도학습</h2><p id="ef590a28-1186-4804-9864-439f9cfd7d13" class="">
</p><p id="aeb71d81-5a3d-40da-92bd-0bd284684095" class="">딥러닝을 종단간 기게학습이라고도 한다. 여기서 종단간은 &#x27;처음부터 끝까지&#x27;라는 의미로, 데이터(입력)에서 목표한 결과(출력)를 사람의 개입 없이 얻는다는 뜻을 담고 있다.</p><p id="b7fd7f83-9d5a-4b71-bc2c-0c5e34f50632" class="">
</p><figure id="fba184c7-1a6e-4905-8361-32fbde286780" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled.png"><img style="width:967px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled.png"/></a></figure><ul id="dd967db1-b71c-40d2-b10a-e6c8cac9e92e" class="bulleted-list"><li><strong>SIFT: Scale Invariant Feature Trasform</strong><p id="fa8ae628-e531-43df-8eca-8bfa704a74cf" class="">사진에서 코너점등 식별이 용이한 특징점들을 선택한 후에 각 특징점을 중심으로 한 로컬 패치에 대해 특징 벡터를 추출한 것</p><p id="ddaea975-bc2a-4f53-bf36-182cd2460d53" class="">이미지의 크기 및 회전에 영향을 받지 않는 특징점을 추출하는 알고리즘</p><p id="571a9f6d-0c41-4f99-8e78-370dd55dcdc5" class="">
</p></li></ul><ul id="426a40c4-9620-4200-9861-62066d5be222" class="bulleted-list"><li><strong>HOG: Histogram of Oriented Gradient</strong><p id="71b85885-fbee-43de-9033-da490337d332" class="">대상영역을 일정 크기의 셀로 분할하고, 각 셀마다 edge 픽셀들의 방향에 대한 히스토그램을 구한 후 이들 히스토그램 bin 값들을 일렬로 연결한 벡터이다.</p><p id="ec2f8ed7-c37a-4e84-b77b-9724d58c0fea" class="">영상의 밝기 변화, 조명 변화에 덜 민감한 알고리즘</p></li></ul><p id="24d8187b-e9d1-4aa6-90eb-e107b5746715" class="">
</p><p id="820ba1d3-23f4-46bc-911f-ece886777cb0" class="">
</p><h2 id="ab22744d-ce8f-4980-b05b-052efdf5766b" class="">1.2 훈련 데이터와 시험 데이터</h2><p id="0db2d8d7-dc26-481c-bad0-c8480c806763" class="">
</p><p id="be2a2f9d-998a-4d73-904a-4a231c37c65a" class="">❌주의❌</p><p id="63e65a81-d7f7-4ca2-8d78-aca27aba83f4" class="">범용적으로 사용할 수 있는 모델을 원하기에 <strong>범용능력</strong>을 제대로 평가하기 위해 훈련 데이터와 시험 데이터를 분리 하여야 한다.</p><p id="eab4eb0f-2de1-4d71-8b9b-2d964491cd51" class="">
</p><p id="9b92dc0c-eb68-474b-a77d-52645b65ddb3" class="">
</p><p id="a4f4cd7f-45fb-4b96-bc69-90a8ad834a1d" class=""><strong>범용능력</strong>: 아직 보지못한 데이터로도 문제를 올바르게 풀어내는 능력 </p><p id="db844fbd-f9af-4d7c-b79b-384666023241" class=""><strong>오버피팅</strong>: 한 데이터셋에만 지나치게 최적화된 상태</p><h1 id="fe18ab4b-3504-490f-9e5d-0aa341b3e5ba" class="">2. 손실 함수</h1><p id="0d679d50-7a6b-4ef5-8436-c708fb452605" class="">신경망은 <strong>손실함수</strong>를 기준으로 최적의 매개변수 값을 탐색 합니다.</p><p id="abdc6cb5-68f0-4470-897d-c1cd6784b9e9" class="">
</p><p id="85670a46-26ac-4b2a-995a-e1b8e42de7a6" class=""><strong>손실함수</strong>: 신경망 선응의 &#x27;나쁨&#x27;을 나타내는 지표로 현재의 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타낸다.</p><h2 id="1fa307b2-2168-4782-99d5-8eaeef59cedc" class="">2.1 오차제곱합</h2><p id="a95c3df9-83f8-4d94-b110-1135d8d49af9" class="">가장 많이 쓰이는 손실함수는 오차제곱 입니다.</p><p id="e3007c28-58fb-400c-81c3-436bcb7fa3ab" class="">
</p><figure id="643544c3-fffe-4bf9-85db-c795086dba31" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%201.png"><img style="width:465px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%201.png"/></a></figure><p id="15584c22-d3a0-4152-9a01-b604edb18f75" class="">여기서 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>는 신경망의 출력, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>는 정답 레이블 , k 는 데이터의 차원수를 나타냅니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="909ac3f6-2830-4f58-b7ec-dbd53b6686a4" class="code code-wrap"><code>y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span></code></pre><p id="ea67eb9f-8967-4cbc-a839-8585cbe717f8" class="">출력 y는 소프트맥스 함수의 출력입니다.</p><p id="9a343f96-60c2-4e8c-adbd-4ae27d6efa89" class="">소프트맥스 함수의 출력은 확률로 해석 할 수 있으므로 이미지가 &#x27;0&#x27; 일 확률은 0.1, &#x27;1&#x27;일 확률은 0.05 라고 해석 됩니다.</p><p id="ba32a891-f692-48f3-a243-b27a1cea3906" class="">
</p><p id="4980330c-3517-41fc-b8ef-4703a11c04e3" class="">정답레이블인 t는 정답을 가리키는 위치의 원소는 1로 하고 그외는 0으로 나타내는 표기인 원-핫 인코딩을 진행하였습니다.</p><p id="d413705b-81b3-498b-99b4-351873f0bfdc" class="">
</p><p id="51915d04-3222-4947-baba-a58990fd1cb4" class="">파이썬으로 오차제곱합 코드는 아래와 같습니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="f2a89046-b998-4dbf-a88a-80f2755d045a" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">sum_squares_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>y<span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span> 

y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

sum_squares_error<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">0.09750000000000003</span></code></pre><p id="b7ece8d0-5110-4629-b043-672ad35b227a" class="">
</p><p id="068381e3-0a94-4dca-ab98-660c8cc4df59" class="">y 값이 7일 확률이 가장 높다고 추정하면 손실함수가 높아진 것을 볼 수 있습니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="96ffc540-f5a7-4bec-8208-59b9de08e663" class="code code-wrap"><code>y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

sum_squares_error<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#결과값</span>
<span class="token number">0.5975</span></code></pre><p id="5037e141-89c9-4f07-a9da-eadebd1ced04" class="">
</p><p id="f82b5ac6-78f9-46e2-9d2a-3090154389fb" class="">두 가지 예의 결과로 첫번째 추정 결과가 정답에 더 가까울 것으로 판단할 수 있습니다.</p><p id="cfa58252-d44c-4ce2-8e46-cf5470612dee" class="">
</p><h2 id="2d5038ba-b88f-4d17-892e-2ec37da69afd" class="">2.2. 교차 엔트로피 오차</h2><p id="fbf0fa7e-b636-4c90-a5b9-850cd8431df9" class="">또 다른 손실 함수로써 <strong>교차 엔트로피 오차</strong>를 사용합니다.</p><p id="03cef7bc-bdcf-42f2-9206-2b1cb6cfb090" class="">
</p><figure id="8d66fd97-a68d-4549-a1a3-5e345dac9355" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%202.png"><img style="width:414px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%202.png"/></a><figcaption>식 4.2</figcaption></figure><p id="e299cdee-7562-4038-af4f-c1a9dc4e0b91" class="">❌주의❌</p><p id="528f58f0-36f1-4d96-8efe-a6c8e823e0b3" class="">여기서 log는 밑이 e인 자연로그입니다.</p><p id="91d4a511-1250-41e6-88a3-e67741aaf503" class="">
</p><p id="330e1384-d765-40dc-b68c-21f660b80109" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>는 신경망의 출력, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>는 정답 레이블 입니다.</p><p id="8eea0f9f-93a9-460e-bf49-71f12d2476a6" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0입니다.  </p><p id="d2d3ba3d-03ef-4440-aefe-29cd99cfb408" class="">교차엔트로피 오차는 정답일 때의 출력이 전체 값을 결정하게 됩니다.</p><p id="de12d385-b847-43ce-b8d8-e9741d7f9e1c" class="">
</p><ul id="c5aa37b9-100b-4d91-aa32-49010330e6fe" class="bulleted-list"><li>자연로그 y=log(x)의 그래프</li></ul><figure id="4b5b3144-3b49-4936-bdc3-b2d01c5ab850" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%203.png"><img style="width:940px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%203.png"/></a></figure><p id="f5926061-5d20-406f-8557-e0dafaea9e88" class="">x가 1일때는 y는 0이 되고 x가 0에 가까워질수록 y의 값은 점점 작아집니다. 교차엔트로피도 마찬가지로 정답에 해당하는 출력 커질수록 0에 다가가다가 그 출력이 1일 때 0이됩니다.</p><p id="96f305a3-7c9b-485d-9408-68172467f191" class="">
</p><p id="28f9fedc-0f48-4a6d-bfbe-09c7286e262c" class="">교차엔트로피 오차를 구현합니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="b58ffe0b-3f52-410b-86e9-05bab89b99ba" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">cross_entropy_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
  delta <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span>
  <span class="token keyword">return</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>t <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y <span class="token operator">+</span> delta<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p id="a8a1958e-6b68-4522-b936-1235634e7505" class="">❌주의❌</p><p id="8e2e2892-5b97-4876-8a1f-afabdab0f8f5" class="">delta를 더한이유는 np.log()함수에 0을 입력하면 -inf가 되어 더 이상 계산을 진행할 수 없게 되기 때문입니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="1fbafac9-5757-4bbc-a46e-3c3f99207720" class="code code-wrap"><code><span class="token comment">#첫 번째 예</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

cross_entropy_error<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">0.510825457099338</span>

<span class="token comment">#두 번째 예</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

cross_entropy_error<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">2.302584092994546</span></code></pre><p id="014f29cf-3954-4ef7-b054-2cbaeec40147" class="">결과값을 보면 앞서 진행한 오차제곱합과 판단이 일치합니다.</p><h2 id="4ca2d94f-21b0-4c76-92fa-1d7213ae412d" class="">2.3 미니배치 학습</h2><p id="29561383-9f0a-4abc-ab8e-91f194945222" class="">
</p><p id="29868e8c-d411-4036-a500-7180ebf6f4f0" class="">MNIST 데이터셋은 훈련 데이터가 60,000개 이므로 모든 데이터를 대상으로 손실 함수의 합을 구할려면 시간이 걸리기에 신경망 학습에서 훈련 데이터로부터 일부만 골라 학습을 수행한다.</p><p id="46a285d4-0efb-445e-9eee-a9f91281bb10" class="">그 일부를 미니배치라고 하며 가령 60,000장의 훈련 데이터 중에서 100장을 무작위로 뽑은 학습 방법이 미니배치 학습이다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="bb61eeba-4a24-4b35-a14a-49f8bcec5faf" class="code code-wrap"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></code></pre><p id="fafabd0f-dce8-42ca-8d04-b63b3d74595c" class="">코드를 돌린 결과 훈련 데이터는 60,000개이고 입력 데이터는 784열인 이미지 데이터임을 알 수 있다. 정답 레이블을 10줄짜리 데이터이며 x_train, t_train의 모습은 각각(60000,784)와 (60000,10)이 된다.</p><p id="82061c29-b333-4466-a7fa-7609232fd7ed" class="">
</p><p id="90e2653a-1617-4435-b189-4c6618d584d4" class="">만약 훈련 데이터에서 무작위로 10장만 빼내려면 np.random.choice()함수를 쓰면 된다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="f1fd450d-801b-4e52-a69a-25bef468ef2c" class="code code-wrap"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
batch_size <span class="token operator">=</span> <span class="token number">10</span>
batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
x_batch <span class="token operator">=</span> x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
t_batch <span class="token operator">=</span> t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span></code></pre><p id="17d8b974-469c-44b2-b162-97c156bcd6de" class="">
</p><p id="088e768c-9152-4cd8-8942-eb60945dacf3" class="">0~60000 미만의 수 중에서 무작위로 10개 골라내기 위해서는 np.random.choice(60000,10) 사용한다.</p><h2 id="43347660-c0cc-4e74-8bd4-6f75b2d9b038" class="">2.4 (배치용) 교차 엔트로피 오차 구현하기</h2><p id="59bb50ee-0000-47fd-9ba1-39084821a84f" class="">
</p><p id="c2b658db-2981-432e-a14a-8588f2e41b0d" class="">미니배치 같은 배치 데이터를 지원하는 교차 엔트로피 오차를 구현하기 위해서는 교차 엔트로피 오차(데이터를 하나씩 처리하는 구현)를 조금만 바꿔주면 된다.</p><p id="c59b5ee4-0dcb-4657-bbd4-f7a99965ba4c" class="">
</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="604372ad-aaa8-4773-a764-b09c26747b44" class="code code-wrap"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">cross_entropy_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token comment"># 차원이 1 차원일때</span>
    <span class="token keyword">if</span> y<span class="token punctuation">.</span>ndim <span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>

        t <span class="token operator">=</span> t<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>t<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
        y <span class="token operator">=</span> y<span class="token punctuation">.</span> reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>size<span class="token punctuation">)</span>

    batch_size <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>t<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token operator">+</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size</code></pre><p id="4e613e7e-8a76-4909-8857-1b853f7e5ece" class="">위 코드는 데이터가 하나인 경우와 데이터가 배치로 묶여 입력될 경우 모두를 처리할 수 있도록 구현 되었다.</p><p id="9e27fcb3-f5ba-4476-a7f8-8f278c3cb9f9" class="">이 코드에서 y는 신경망의 출력, t는 정답 레이블이다. y가 1차원이라면, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape 함수로 데이터의 형상을 바꿔준다.</p><p id="5d49e75f-ad26-4d49-841e-967b9d6d6180" class="">배치의 크기로 나눠 정규화하고 이미지 1장당 평균의 교차 엔트로피 오차를 계산한다.</p><p id="77097a92-5087-4b12-883d-0d795c4b9eb9" class="">
</p><p id="74f53df2-8afa-488c-a488-db96ec6aabdd" class="">정답레이블이 원-핫 인코딩이 아니라 &#x27;2&#x27;나 &#x27;7&#x27;등의 숫자 레이블로 주어졌을 때의 교차 엔트로피 오차는 다음과 같이 구현 할 수 있습니다.</p><h2 id="c73cec60-982c-4ad7-b2f9-db6a6a21ee62" class="">2.5 왜 손실 함수를 설정하는가?</h2><p id="b91fa2b6-8a3b-4672-9048-156eac8d7f87" class="">
</p><ul id="5a841d8b-d2d9-436b-9c57-2a816efe9ab1" class="bulleted-list"><li>정확도라는 지표를 놔두고 손실 함수의 값이라는 우회적 방법을 택하는 이유는?<p id="25b0314a-f340-420e-89cb-4222eb6198b3" class="">정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되어 갱신할 수 없기 때문이다.</p><p id="1e4aa24f-9436-43cd-ac6a-a2519e5e7ae0" class="">정확도는 매개변수의 미소한 변화에는 거의 반을을 보이지않고 반응이 불연속적으로 갑자기변한다. (계단함수를 활성화 함수로 사용하지 않는 이유와도 같다.)</p></li></ul><h1 id="59d2a380-9dd2-43cf-9239-ab3030661d31" class="">3. 수치 미분</h1><h2 id="5a0dc621-6618-43e4-b871-abf1f64a8d8b" class="">3.1 미분</h2><p id="3707a4e0-4990-46d4-b876-4c963ac33193" class="">
</p><figure id="4678ed79-e769-4194-9ada-3478e897963c" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%204.png"><img style="width:657px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%204.png"/></a></figure><p id="b4954f4f-851d-44c6-ba14-9075a7742c8e" class="">
</p><p id="65867218-7d0a-4874-a8df-111f3fc0aa58" class="">함수의 이름은 <strong>수치 미분</strong>에서 따온 numerical_diff(f,x)로 한다.</p><p id="0def69d7-eccf-4d01-98a9-509971167167" class=""><strong>수치 미분</strong>: 아주작은 차분으로 미분하는것</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="ac51ec7f-b4be-463c-8162-d16ecf1a69d6" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">numerical_diff</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    h <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span> <span class="token comment"># 0.0001</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x<span class="token operator">+</span>h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span></code></pre><h2 id="23192ffe-a32c-41ff-b9f8-402886fbe70d" class="">3.2 수치 미분의 예</h2><p id="c09ca576-0655-4a9a-b60c-3ad8fb523614" class="">
</p><p id="c1d0683f-b812-4452-b2c0-f0192eacac14" class="">아래 코드는 <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>0.01</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>0.1</mn><mi>x</mi></mrow><annotation encoding="application/x-tex">y=0.01x^2 + 0.1x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord mathdefault">x</span></span></span></span></span><span>﻿</span></span>를 나타낸 파이썬 코드이다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="f4e370c4-db88-402d-adfe-2ba10065de5f" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">function_1</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> <span class="token number">0.01</span><span class="token operator">*</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span>x</code></pre><p id="f387a353-0b9c-4d07-916b-87c2d4a11139" class="">이어서 이 함수를 그려보면</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="07fb5b6d-dd3b-4d33-b94b-5404c7f88bd1" class="code code-wrap"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt

<span class="token keyword">def</span> <span class="token function">function_1</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> <span class="token number">0.01</span><span class="token operator">*</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span>x

x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># 0에서 20까지 0.1 간격의 배열 x를 만든다(20은 미포함).</span>
y <span class="token operator">=</span> function_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'f(x)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><figure id="e517c812-efcf-49c6-8dc1-48764b21fd72" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%205.png"><img style="width:576px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%205.png"/></a></figure><p id="94e7368d-c7ff-42a3-a63e-129e80d5efed" class="">계산된 미분 값은 x에 대한 f(x)의 변화량, 즉 함수의 기울기에 해당한다. 그리고 x가 5일때와 10일 때의 진정한 미분은 차례로 0.2와 0.3이다.</p><p id="0879d439-e447-4da2-960c-22a843049680" class="">파이썬 결과는 아래와 같다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="c1231f4d-9bbc-4628-a326-f4c456c4565d" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">numerical_diff</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    h <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span> <span class="token comment"># 0.0001</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x<span class="token operator">+</span>h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">function_1</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> <span class="token number">0.01</span><span class="token operator">*</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span>x

<span class="token keyword">print</span><span class="token punctuation">(</span>numerical_diff<span class="token punctuation">(</span>function_1<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>numerical_diff<span class="token punctuation">(</span>function_1<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">0.1999999999990898</span>
<span class="token number">0.2999999999986347</span></code></pre><p id="921cee5d-e41e-4f30-aaa9-18b0a8450aba" class="">앞의 수치 미분과 결과를 비교하면 그 오차가 매우 작음을 알 수 있습니다.</p><h2 id="d492c191-8692-4e08-9f29-7a1369bfde4b" class="">3.3 편미분</h2><p id="e95f22d6-08e5-4535-a148-34146079800a" class="">
</p><p id="43484050-6673-4ecc-87e8-45b44fae0749" class="">편미분 : 변수가 여럿인 함수에 대한 미분</p><p id="900f8686-c4eb-4a09-9976-a5de8dbc4d9a" class="">
</p><figure id="8e83f9e3-c412-4018-b0d3-a05a84a3d312" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%206.png"><img style="width:437px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%206.png"/></a></figure><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="8addb4d1-d1de-40c8-95d4-8fa54cf32a8b" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>s<span class="token operator">*</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>  <span class="token comment">#또는 return np.sum(x**2)</span></code></pre><p id="779b5d21-8563-4b4a-beb2-18dec11da266" class="">인수 x는 넘파이 배열이라고 가정하며 넘파이 배열의 각 원소를 제곱하고 그 합을 구할 간단한 형태로 구현할 수 있다.</p><p id="ba650d54-8bf4-4363-83fa-cce79ed76006" class="">
</p><ul id="3746f4b5-c66c-46fe-bc53-defe571b4fb4" class="bulleted-list"><li>문제 1: x0=3, x1=4일 때, x0에 대한 편미분을 구하라</li></ul><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="9e110c3e-8bd0-4de9-9104-a747b1c876ec" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">numerical_diff</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    h <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span> <span class="token comment"># 0.0001</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x<span class="token operator">+</span>h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">function_tmp1</span><span class="token punctuation">(</span>x0<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x0 <span class="token operator">*</span> x0 <span class="token operator">+</span> <span class="token number">4.0</span><span class="token operator">**</span><span class="token number">2.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>numerical_diff<span class="token punctuation">(</span>function_tmp1<span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">6.00000000000378</span></code></pre><p id="7ff0470e-89df-4c87-bb95-51238cbce8c9" class="">
</p><ul id="66bbc2aa-5e91-4f7e-bbbd-eaef3a2cf768" class="bulleted-list"><li>문제 2: x0=3, x1=4일때, x1에 대한 편미분을 구하라</li></ul><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="7b770d8b-50c8-4372-83a1-eb35a48e1bd2" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">numerical_diff</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    h <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span> <span class="token comment"># 0.0001</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x<span class="token operator">+</span>h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">function_tmp2</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x1 <span class="token operator">*</span> x1 <span class="token operator">+</span> <span class="token number">3.0</span><span class="token operator">**</span><span class="token number">2.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>numerical_diff<span class="token punctuation">(</span>function_tmp2<span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token number">7.999999999999119</span></code></pre><p id="98b933ae-eee8-4233-a016-c683fc93250a" class="">
</p><h1 id="e829f8c1-efcb-43b6-b148-449097109e24" class="">4. 기울기</h1><p id="b12f40da-d296-419a-a7a1-f45d1cd1035c" class="">x0와 x1의 편미분을 동시에 계산하는 방법</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="7302c899-2b8c-469d-9ed8-84f79ad04869" class="code code-wrap"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    h <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span> <span class="token comment"># 0.0001</span>

    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># x와 형상이 같은 배열을 생성</span>

    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tmp_val <span class="token operator">=</span> x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        <span class="token comment"># f(x+h) 계산</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val<span class="token operator">+</span> h
        fxh1 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># f(x-h) 계산</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val<span class="token operator">-</span> h
        fxh2 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>fxh1 <span class="token operator">-</span> fxh2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val<span class="token comment"># 값 복원</span>

    <span class="token keyword">return</span> grad</code></pre><p id="0609f34b-4cf8-44b6-98fb-771ca6329bfd" class="">여기서 numerical_gradient(f,x) 함수의 구현은 복잡해 보이지만, 동작 방식은 변수가 하나일 때의 수치 미분과 거의 같다. </p><p id="88b558d7-4997-474c-bbda-0fd7690fa8ab" class="">f는 함수, x는 넘파이 배열이므로 넘파이 배열 x의 각 원소에 대해서 수치 미분을 구한다.</p><p id="eedf73c7-1fb5-40ac-9eb5-09f28934853d" class="">기울기는 각 지점에서 낮아지는 방향을 가리킨다. 즉, 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향이다.</p><h2 id="a63a9861-928e-4049-9774-225b863457f8" class="">4.1 경사법(경사 하강법)</h2><p id="f523e4e7-9947-459d-ab22-e93c552d36d4" class="">
</p><p id="f93dcfa7-6c93-469e-a5e5-0e1b8e7f46f4" class="">신경망에서 최적의 매개변수 중 최적이란 손실 함수가 최솟값이 될 때의 매개변수 값이다. </p><p id="a1e26c57-2960-4087-86e9-4a34ba68c6fc" class="">하지만 일반적인 손실함수는 복잡하며 최솟값이 되는 곳을 짐작하기 어렵다. </p><p id="9188e5e8-753f-4853-a2f6-4af78ad2f3ca" class="">이런 상황에서 기울기를 잘 이용해 함수의 최솟값(또는 가능한 한 작은 값)을 찾으려는 것이 경사법이다.</p><p id="f534d38f-9ee1-45d9-8862-c10bd6da2a01" class="">
</p><p id="a7e2813f-05f1-4a72-85ee-834c88e66e76" class="">함수가 안장점이 되는 장소에서는 기울기가 0이다.</p><p id="df3674cd-45bb-4382-9c15-8f408d430d8d" class="">안장점은 어느방향에서보면 극대값이고 다른 방향에서 보면 극솟값이 되는 점이다.</p><p id="5903aef5-927f-4288-be5b-bb7383bbaec1" class="">
</p><p id="04588ab7-46c9-47a5-b927-7cf679a88a9f" class="">❌주의❌</p><p id="e3744c44-1f1f-4e03-89ab-4b7e1606fc39" class="">경사법은 기울기가 0인 장소를 찾지만 그것이 반드시 최솟값이라고는 할 수 없습니다 그 이유는 고원(local minimum)이라 하는 학습이 진행되지 않는 정체기에 빠질 수 있기 때문입니다.</p><p id="1ae23673-7ff7-4d5f-8268-1b7a46531493" class="">각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기라는 것이다. </p><figure id="98d99b4c-80bf-4818-86ea-c3934793bbdd" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%207.png"><img style="width:420px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%207.png"/></a></figure><p id="2439a635-8f9a-487f-b0ac-e640ebe69a86" class="">경사법을 수식으로 나타낼 때 갱신하는 양을 학습률이라고 표현한다.</p><p id="7703c678-b067-48ca-b3ce-56791c7d5ac2" class="">즉, 한 번의 학습으로 얼마만큼 학습해야 할지를 정하는 것이 학습률이다.</p><p id="23c57674-e7b8-4caa-8e68-6e39faf59112" class="">
</p><p id="6d7e5f24-24e7-4636-82ca-aa64c4d18b4f" class="">경사하강법을 구현하면 아래와 같습니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="884bc703-27a9-491d-b314-61a70224edf0" class="code code-wrap"><code><span class="token comment">#경사하강법</span>
<span class="token keyword">def</span> <span class="token function">gradient_descent</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> init_x

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>step_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        grad <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        x <span class="token operator">-=</span> lr <span class="token operator">*</span> grad
    <span class="token keyword">return</span> x</code></pre><p id="4adc90da-c67b-4bc4-b63e-daea3ccdb22d" class="">인수 f는 최적화하려는 함수, init_x는 초깃값, lr은 learning rate를 의미하는 학습률, step_num은 경사법에 따른 반복횟수를 뜻한다.</p><p id="b665e39a-e921-42ec-91f4-bbbfdac79262" class="">
</p><p id="a95de11b-a4b1-4ab4-b767-0bc298dcba09" class="">문제 :  경사법으로 f(x0. x1)= x0**2+x1**2 최솟값을 구하라</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="b2dd8df7-8614-433b-9776-7504b96bfba1" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>

init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">6.11110793e-10</span>  <span class="token number">8.14814391e-10</span><span class="token punctuation">]</span></code></pre><p id="5efafec3-f6a4-4ba4-b420-0b97896608d9" class="">결과값이 거의 0에 수렴하는 결과값입니다.</p><p id="acf45136-522c-4369-8bc8-1c599c14d09f" class="">
</p><p id="5a7a1670-de88-4578-b153-2b6472443d7b" class="">반대로 잘못 학습한 경우입니다.</p><ul id="d21a78b3-39d7-4ac5-a0cd-25e1ce581cc2" class="bulleted-list"><li>학습률이 너무 큰 예 : lr = 10.0</li></ul><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="cec5d980-40a9-44dd-a785-1e6f98e5615d" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>

init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span> step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.58983747e+13</span> <span class="token operator">-</span><span class="token number">1.29524862e+12</span><span class="token punctuation">]</span></code></pre><ul id="293487cf-a93b-4de6-88bb-3c3b8842a727" class="bulleted-list"><li>학습률이 너무 작은 예 : lr = 1e-10</li></ul><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="51409dd6-59b0-464e-aac0-9b3a2f952f1c" class="code code-wrap"><code><span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>

init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.99999994</span>  <span class="token number">3.99999992</span><span class="token punctuation">]</span></code></pre><p id="40d6435b-d0a1-45d3-84cc-1d7f26e5def0" class="">
</p><ul id="583e7fc7-dc0e-4f89-b947-d768950f87f3" class="bulleted-list"><li>Note<p id="7df235cb-3c31-47f7-b330-ee436b5110e7" class=""><strong>하이퍼파라미터</strong>: 사람이 직접 설정해야 하는 매개변수</p></li></ul><p id="945922f8-f462-4bf4-8e91-274e67084309" class="">
</p><h2 id="1cd4ef37-86c4-4893-905a-ab0d25866bfb" class="">4.2 신경망에서의 기울기</h2><p id="ee3e1d92-d566-478a-bcdc-f37ec9d0aaf6" class="">
</p><p id="1dbed91d-cce9-481f-ae75-82e336b4ad3a" class="">
</p><p id="b672c4c1-b04a-4b6a-aa78-c7951e3db803" class="">신경망 학습에서의 기울기는 가중치 매개변수에 대한 손실 함수의 기울기이다. </p><p id="ac2f6bc9-a0af-4ba6-83cc-4635f29f2f89" class=""><strong>가중치가 W, 손실 함수가 L</strong>인 신경망 경우 편미분을 한다.</p><p id="b45f4ee4-aee9-43d5-8239-61d3ecf0b08b" class=""><strong>손실 함수 L</strong>이 얼마나 변하는지에 대해서 알려주는 것이 w11이다.</p><p id="1c91eade-175d-49d4-b152-5f191e981418" class="">
</p><figure id="f6b3ee34-d083-4b3f-a7a3-179710b27a76" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%208.png"><img style="width:575px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%208.png"/></a></figure><p id="3988c541-e311-4a4e-b3a7-cd52e4cec858" class="">
</p><p id="e1e8dbb0-e02a-4ffa-9d65-ebcc6f5bb0dc" class="">
</p><p id="fbfe6a64-68b4-4ddf-b9d2-6f2fb15dee5b" class="">기울기를 구하는 코드를 구현하면 아래와 같습니다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="9b3eae5e-1cc3-4313-bcf3-09cd0311c540" class="code code-wrap"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span> 
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> common<span class="token punctuation">.</span>functions <span class="token keyword">import</span> softmax<span class="token punctuation">,</span> cross_entropy_error
<span class="token keyword">from</span> common<span class="token punctuation">.</span>gradient <span class="token keyword">import</span> numerical_gradient

<span class="token keyword">class</span> <span class="token class-name">simpleNet</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> cross_entropy_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        <span class="token keyword">return</span> loss

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> simpleNet<span class="token punctuation">(</span><span class="token punctuation">)</span>

f <span class="token operator">=</span> <span class="token keyword">lambda</span> w<span class="token punctuation">:</span> net<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

dW <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span> net<span class="token punctuation">.</span>W<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>dW<span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2281813</span>   <span class="token number">0.17987652</span> <span class="token operator">-</span><span class="token number">0.40805783</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">0.34227195</span>  <span class="token number">0.26981479</span> <span class="token operator">-</span><span class="token number">0.61208674</span><span class="token punctuation">]</span><span class="token punctuation">]</span></code></pre><p id="c658fc1c-d567-46de-894b-c586b053e365" class="">
</p><h1 id="47d42042-e5c4-4351-82f0-a53bd6004ed3" class="">5. 학습 알고리즘 구현하기</h1><p id="8cd86e4d-d60f-445f-b248-c8a358213a42" class="">
</p><blockquote id="f7de3102-7270-45ef-9ab5-ed2fec2761b4" class="">전체 </blockquote><p id="b286c532-a2cb-4dca-bda5-5e7b3e23d0de" class=""> 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 학습이라 한다.</p><p id="28006d20-7aef-4fc1-903d-b8bebc7db25f" class="">
</p><ul id="eb211da0-c7e7-4e5a-8452-1a7b39981280" class="bulleted-list"><li>1단계-미니배치 </li></ul><p id="67a7f072-8e0c-4cae-9fa5-8d05ed398d41" class="">훈련 데이터 중 일부를 무작위로 가져온다. 미니배치의 손실 함수 값을 줄이는 것이 목표이다.</p><ul id="edaf118d-cb13-4bf5-9fa2-2f59ab556b7c" class="bulleted-list"><li>2단계-기울기 산출 </li></ul><p id="30b30467-e42a-4456-bb91-9088b4b801a6" class="">미니배치의 손실 함수 값을 줄이기 위해 각 가주이 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.</p><ul id="09c9ae7b-f46b-422d-8a32-7bf6a7d0bf80" class="bulleted-list"><li>3단계-매개변수 갱신 </li></ul><p id="c6fccc7f-7b32-4a90-b56f-3b03ad035e46" class="">가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.</p><ul id="d02d9b74-6ec4-4070-8420-da3fe0180aba" class="bulleted-list"><li>4단계<p id="dbb28bc4-9a7d-4bb0-9786-3987a0663bc4" class="">1~3단계를 반복한다.</p></li></ul><p id="f798db70-73e0-4720-affc-f0b1c8e4d7b3" class="">하강법으로 매개변수를 갱신하는 방법이며 이때 데이터를 미니배치로 무작위로 선정하기 때문에 <strong>확률적 경사 하강법</strong>이라 부른다.</p><h2 id="3b4489c7-843b-4a9c-b6fd-ddf72f2cde57" class="">5.1 2층 신경망 클래스 구현하기</h2><p id="471a5774-c7c1-4c57-a1dd-aaaabbfbfb2e" class="">
</p><p id="1f55cd6b-c1be-4877-86e2-5c2d19996328" class="">클래스의 이름은 TwoLayerNet이다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="44005f48-9e16-40d7-889b-013b835bc2e7" class="code code-wrap"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span>  
<span class="token keyword">from</span> common<span class="token punctuation">.</span>functions <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> common<span class="token punctuation">.</span>gradient <span class="token keyword">import</span> numerical_gradient
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">TwoLayerNet</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
    
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> y
        

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> cross_entropy_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y <span class="token operator">==</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> accuracy

    <span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss_W <span class="token operator">=</span> <span class="token keyword">lambda</span> W<span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
        
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> grads
        
    <span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        
        batch_num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        
        <span class="token comment"># forward</span>
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token comment"># backward</span>
        dy <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_num
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dy<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        dz1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dy<span class="token punctuation">,</span> W2<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        da1 <span class="token operator">=</span> sigmoid_grad<span class="token punctuation">(</span>a1<span class="token punctuation">)</span> <span class="token operator">*</span> dz1
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> da1<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>da1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> grads</code></pre><h2 id="21e7f4d6-1b78-40d5-a58d-3cf3e6b0975d" class="">5.2 미니배치 학습 구현하기</h2><p id="029af7d1-d631-4bb7-8a2a-e9e93423f26c" class="">
</p><p id="8013be05-a759-48f0-be30-3868bc06f35d" class="">미니배치 학습이란 훈련 데이터 중 일부를 무작위로 꺼내고, 그 미니배치에 대해서 경사법으로 매개변수를 갱신하는 것이다. TwoLayerNet으로 학습을 수행해본다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="f9ffc692-bc25-412f-9663-001cafb385dc" class="code code-wrap"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist

<span class="token keyword">class</span> <span class="token class-name">TwoLayerNet</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
    
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> y
        

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> cross_entropy_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y <span class="token operator">==</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> accuracy

    <span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss_W <span class="token operator">=</span> <span class="token keyword">lambda</span> W<span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
        
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> grads
        
    <span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        
        batch_num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        
        <span class="token comment"># forward</span>
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token comment"># backward</span>
        dy <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_num
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dy<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        dz1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dy<span class="token punctuation">,</span> W2<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        da1 <span class="token operator">=</span> sigmoid_grad<span class="token punctuation">(</span>a1<span class="token punctuation">)</span> <span class="token operator">*</span> dz1
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> da1<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>da1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> grads

<span class="token comment"># 시작</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

network <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

iters_num <span class="token operator">=</span> <span class="token number">10000</span>  <span class="token comment">#반복횟수</span>
train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
batch_size <span class="token operator">=</span> <span class="token number">100</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

iter_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>train_size <span class="token operator">/</span> batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iters_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 미니배치 획득</span>
    batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
    x_batch <span class="token operator">=</span> x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    t_batch <span class="token operator">=</span> t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    
    <span class="token comment">#기울기 계산</span>
    <span class="token comment">#grad = network.numerical_gradient(x_batch, t_batch) #성능 개선판@</span>
    grad <span class="token operator">=</span> network<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    
    <span class="token comment">#매개변수 갱신</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'W1'</span><span class="token punctuation">,</span> <span class="token string">'b1'</span><span class="token punctuation">,</span> <span class="token string">'W2'</span><span class="token punctuation">,</span> <span class="token string">'b2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        network<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> grad<span class="token punctuation">[</span>key<span class="token punctuation">]</span>

    <span class="token comment">#학습결과 기록</span>
    loss <span class="token operator">=</span> network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><p id="a630d51f-d599-4f31-9f21-f6123f87e6ca" class="">
</p><figure id="65035562-f702-41bb-849b-eb62c63abced" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%209.png"><img style="width:528px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%209.png"/></a></figure><p id="3ed3c218-2bc8-4704-b67e-40658776d996" class="">위 코드를 통해 신경망의 가중치 매개변수가 학습 횟수가 늘어가면서 손실 함수의 값이 줄어드는 것을 확인할 수 있다.</p><p id="16922a17-5fa4-45d9-bb02-4d04a7d8c534" class=""> 즉, 신경망의 가중치 매개변수가 데이터를 반복해서 학습함으로서 최적 가중치 매개변수로 서서히 다가서고 있다.</p><h2 id="46b16d6f-167f-43bd-a9c4-9a2e2f5baf01" class="">5.3 시험 데이터로 평가하기</h2><p id="cef42c30-0061-485f-a783-20406bb757ba" class="">
</p><ul id="9b229a3c-9d05-42d3-9b1e-d61eecc69928" class="bulleted-list"><li>epoch: 하나의 단위<p id="c556732e-1561-4c38-84f3-a2e42d1b14e4" class="">1epoch은 학습에서 훈련 데이터를 모두 소진 했을 때의 횟수에 해당 합니다.</p><p id="f1d5988e-4982-4ff1-b40a-c973acf4e866" class="">예를들어 훈련 데이터 10000개를 100개의 미니배치로 학습할경우 확률적 경사 하강법을 100회 반복하면 모든 훈련데이터를 소진한게 됩니다. 이 경우 100회가 1에폭이 됩니다.</p><p id="c08f047f-7010-49fb-bd08-8bbca7a3c819" class="">
</p></li></ul><p id="f1a94746-2d61-491a-be12-c317c6e86a05" class="">신경망 학습의 목표는 범용적인 능력을 익히는 것이다. 오버피팅 일으키지 않는지 확인해야한다</p><p id="82887519-e81e-48e7-9ccf-39d2ad6a4575" class="">. 아래는 평가하기 위한 코드이다.</p><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css')</style><pre id="990f4fdf-2102-42b2-9177-ceb4bf2875e0" class="code code-wrap"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span>  
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist
<span class="token keyword">from</span> two_layer_net <span class="token keyword">import</span> TwoLayerNet


<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

network <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

iters_num <span class="token operator">=</span> <span class="token number">10000</span>  
train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
batch_size <span class="token operator">=</span> <span class="token number">100</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

iter_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>train_size <span class="token operator">/</span> batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iters_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token comment">#미니배치 획득</span>
    batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
    x_batch <span class="token operator">=</span> x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    t_batch <span class="token operator">=</span> t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    
    <span class="token comment">#기울기 계산</span>
    <span class="token comment">#grad = network.numerical_gradient(x_batch, t_batch) #성능개선판</span>
    grad <span class="token operator">=</span> network<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    
		<span class="token comment">#매개변수 갱신</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'W1'</span><span class="token punctuation">,</span> <span class="token string">'b1'</span><span class="token punctuation">,</span> <span class="token string">'W2'</span><span class="token punctuation">,</span> <span class="token string">'b2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        network<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> grad<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    <span class="token comment">#학습경과기록</span>
    loss <span class="token operator">=</span> network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> i <span class="token operator">%</span> iter_per_epoch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        train_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span>
        test_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span>
        train_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        test_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train acc, test acc | "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">", "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>


markers <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span class="token punctuation">}</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_acc_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> train_acc_list<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> test_acc_list<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test acc'</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"epochs"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#결과값</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.09751666666666667</span><span class="token punctuation">,</span> <span class="token number">0.0974</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.7877333333333333</span><span class="token punctuation">,</span> <span class="token number">0.7941</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.876</span><span class="token punctuation">,</span> <span class="token number">0.8794</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.8978666666666667</span><span class="token punctuation">,</span> <span class="token number">0.9015</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9069166666666667</span><span class="token punctuation">,</span> <span class="token number">0.9106</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9148666666666667</span><span class="token punctuation">,</span> <span class="token number">0.917</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9193666666666667</span><span class="token punctuation">,</span> <span class="token number">0.922</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.92325</span><span class="token punctuation">,</span> <span class="token number">0.924</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9270166666666667</span><span class="token punctuation">,</span> <span class="token number">0.9286</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.93135</span><span class="token punctuation">,</span> <span class="token number">0.9325</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9344666666666667</span><span class="token punctuation">,</span> <span class="token number">0.9352</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.93685</span><span class="token punctuation">,</span> <span class="token number">0.9367</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9397166666666666</span><span class="token punctuation">,</span> <span class="token number">0.9392</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9416166666666667</span><span class="token punctuation">,</span> <span class="token number">0.9409</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9438833333333333</span><span class="token punctuation">,</span> <span class="token number">0.9417</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9454333333333333</span><span class="token punctuation">,</span> <span class="token number">0.9434</span>
train acc<span class="token punctuation">,</span> test acc <span class="token operator">|</span> <span class="token number">0.9475166666666667</span><span class="token punctuation">,</span> <span class="token number">0.9451</span></code></pre><figure id="9c66d170-cde4-432b-8930-46416a3cf0b0" class="image"><a href="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%2010.png"><img style="width:723px" src="CHAPTER%204%20%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%20%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%20fba184c71a6e4905836132fbde286780/Untitled%2010.png"/></a></figure><p id="37af1048-8232-4ad2-b9e5-c11780ddd8e8" class="">train 과 test간의 간격이 없으므로 오버피팅이 일어나지 않았다.</p><h1 id="3345f9c7-4bab-4f41-8d19-51a3913dc6d1" class="">6. 정리</h1><ul id="97f00681-caf9-4bf1-8091-df44dc84f42d" class="bulleted-list"><li>기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용한다</li></ul><ul id="e600bc99-9f12-4f75-ab7b-80a3f0e20f0c" class="bulleted-list"><li>훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다.</li></ul><ul id="244545e3-ba71-44f1-9daa-07834cdf1075" class="bulleted-list"><li>신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다.</li></ul><ul id="77974605-3a53-4abc-ad68-5b3b9b1eafd7" class="bulleted-list"><li>가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다.</li></ul><ul id="9b0e8483-4647-4d08-be26-215a9826f06a" class="bulleted-list"><li>아주 작은 값을 주었을 떄의 차분으로 미분하는 것을 수치 미분이라고 한다.</li></ul><ul id="d7b6104f-14ce-4c60-9d6e-3751525bb26b" class="bulleted-list"><li>수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.</li></ul><ul id="65a8dc0e-75c7-479d-8a92-3108bcc9266f" class="bulleted-list"><li>수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 (다소 복잡한) 오차역전파법은 기울기를 고속으로 구할 수 있다.</li></ul><p id="3b773121-02b1-4cbf-80d5-e9b2f9531bcc" class="">
</p></div></article></body></html>